<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Vision Transformer | igzat1no&#39;s blog</title>
  <link rel="stylesheet" href="/css/fonts/Chinese-normal-normal.min.css">
  <link rel="stylesheet" href="/css/fonts/ChineseMono-normal-normal.min.css">
  <link rel="stylesheet" href="/css/fonts/Chinese-italic-normal.min.css">
  <link rel="stylesheet" href="/css/fonts/Chinese-normal-bold.min.css">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <meta name="description" content="Pre-trained on large amounts of data, Vision Transformer (ViT) attains excellent results compared to sota and requires fewer computational resources to train.">
  
  
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  
    <link rel="stylesheet" href="/fancybox/jquery.fancybox-1.3.4.css">
  
  
    <link rel="stylesheet" href="/katex/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">

    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script defer src="/katex/katex.min.js" integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>

    <!-- To automatically render math in text elements, include the auto-render extension: -->
    <script defer src="/katex/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
    <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: '\\(', right: '\\)', display: false},
            {left: '\\[', right: '\\]', display: true}
          ],
          throwOnError : false
        });
      });
    </script>
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <div id="nav-outer">
  <nav id="main-nav" class="outer">
    <a id="main-nav-toggle" class="nav-icon"></a>
    
      <a class="main-nav-link" href="/">Home</a>
    
      <a class="main-nav-link" href="/archives">Posts</a>
    
      <a class="main-nav-link" href="/about">About</a>
    
    <div class="main-nav-space-between"></div>
    
  </nav>
</div>
<div id="header-title">

  
</div>

      <div id="content" class="outer">
        <section id="main"><article id="post-ViT" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/06/26/ViT/" class="article-date">
  <time class="dt-published" datetime="2022-06-26T20:53:38.000Z" itemprop="datePublished">2022-06-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Vision Transformer
    </h1>
  

      </header>
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Pre-trained on large amounts of data, Vision Transformer (ViT) attains excellent results compared to sota and requires fewer computational resources to train.</p>
<span id="more"></span>
<h1 id="introduction">Introduction</h1>
<p>split an image into patches</p>
<p>直接把 patch 的内容 embed 当成序列扔进 transformer</p>
<p>在中等大小的数据集上训练时<span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span>比同等大小的 ResNet 要差一些<span class="bd-box"><h-char class="bd bd-beg"><h-inner>；</h-inner></h-char></span>在大型数据集<span class="bd-box"><h-char class="bd bd-end"><h-inner>（</h-inner></h-char></span>14M-300M images<span class="bd-box"><h-char class="bd bd-beg"><h-inner>）</h-inner></h-char></span>上训练时<span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span>ViT 效果大于等于 SOTA<span class="bd-box"><h-char class="bd bd-beg"><h-inner>。</h-inner></h-char></span></p>
<h1 id="method">Method</h1>
<p><img src="image-20220626171812887.png" alt="image-20220626171812887"></p>
<h2 id="vit">ViT</h2>
<p>reshape the image <span class="markdown-them-math-inline">$x \in R^{H \times W \times C}$</span> into a sequence of <span class="markdown-them-math-inline">$x_p \in R^{N \times (P^2 C)}$</span><span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span>其中 <span class="markdown-them-math-inline">$N = HW/P^2$</span> 表示 patch 的数量<span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span><span class="markdown-them-math-inline">$P$</span> 是 patch 的大小<span class="bd-box"><h-char class="bd bd-beg"><h-inner>。</h-inner></h-char></span></p>
<p>embedding 就是 linear projection 从 patch 的大小到 latent vector 的维度 <span class="markdown-them-math-inline">$D$</span></p>
<p>加入了 position embedding (standard learnable 1D position embedding)</p>
<p>perfirm 2D interpolation of the pre-trained position embeddings may now longer be powerful</p>
<h3 id="hybrid-architecture">Hybrid Architecture</h3>
<p>用做完 CNN 以后的 feature map 作为 input sequence 而非原图</p>
<h2 id="fine-tuning-and higher resolution">Fine-Tuning and higher resolution</h2>
<p>pre-train ViT on large datasets and fine-tune to downstream tasks</p>
<p>remove the prediction head and attach <span class="markdown-them-math-inline">$D \times K$</span> 的一个 feedforward layer<span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span><span class="markdown-them-math-inline">$K$</span> 是 downstream task 的 class 数量</p>
<ul>
<li>
<p>ViT-Base 12 768 3072 12 86M</p>
</li>
<li>
<p>ViT-Large 24 1024 4096 16 307M</p>
</li>
<li>
<p>ViT-Huge 32 1280 5120 16 632M</p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      
      
        <a href="/2022/06/26/ViT/#comments" class="article-comment-link">
          <span class="post-comments-count valine-comment-count" data-xid="/2022/06/26/ViT/" itemprop="commentCount"></span>
          留言
        </a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Computer-Vision/" rel="tag">Computer Vision</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Transformer/" rel="tag">Transformer</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2022/06/30/DETR/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          DETR DEtection TRansformer
        
      </div>
    </a>
  
  
    <a href="/2022/06/24/Retina-net/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">
        
          RetinaNet
        
      </div>
    </a>
  
</nav>

  
</article>



  <section id="comments" class="vcomment">

  </section>
</section>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
        <span id="busuanzi_container_site_pv" style='display:none'>Total view count: <span id="busuanzi_value_site_pv"></span></span>
<p>Powered by <a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/">Hexo</a> & Theme <a target="_blank" rel="noopener" href="https://github.com/bill-xia/hexo-theme-mashiro">Mashiro</a> & GitHub Pages</p><p>Copyright © 2024 igzat1no. LICENSE CC BY-NC-SA 4.0.</p>
      
    </div>
  </div>
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Posts</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav>
    

<script src="/js/clipboard.min.js"></script>
<script src="/js/jquery-1.4.3.min.js"></script>

<script src="/fancybox/jquery.fancybox-1.3.4.pack.js"></script>


<script src="/js/script.js"></script>




  
<script src="https://cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js"></script>

<script>
    var GUEST_INFO = ['nick','mail','link'];
    var guest_info = 'nick,mail,link'.split(',').filter(function(item){
        return GUEST_INFO.indexOf(item) > -1
    });
    var notify = 'false' == true;
    var verify = 'false' == true;
    new Valine({
        el: '.vcomment',
        notify: notify,
        verify: verify,
        appId: "k2JFn7Fvw42zZfjmoYffhjGC-gzGzoHsz",
        appKey: "pLfzf8qWKmVAAZPSJ0fXlTlg",
        placeholder: "Leave your footprints here!!",
        pageSize:'10',
        avatar:'wavatar',
        lang:'zh-cn'
    });
</script>



  </div>
</body>
</html>