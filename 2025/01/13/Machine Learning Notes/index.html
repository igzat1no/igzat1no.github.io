<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>machine-learning-notes | igzat1no&#39;s blog</title>
  <link rel="stylesheet" href="/css/fonts/Chinese-normal-normal.min.css">
  <link rel="stylesheet" href="/css/fonts/ChineseMono-normal-normal.min.css">
  <link rel="stylesheet" href="/css/fonts/Chinese-italic-normal.min.css">
  <link rel="stylesheet" href="/css/fonts/Chinese-normal-bold.min.css">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <meta name="description" content="Lecture 2

bottleneck: labeling

overfit


应对 overfit: restrict the representation power -&amp;gt; “regularization”
modern view: overfit 并不是问题，在 SGD 中天生的就">
  
  
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  
    <link rel="stylesheet" href="/fancybox/jquery.fancybox-1.3.4.css">
  
  
    <link rel="stylesheet" href="/katex/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">

    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script defer src="/katex/katex.min.js" integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>

    <!-- To automatically render math in text elements, include the auto-render extension: -->
    <script defer src="/katex/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
    <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: '\\(', right: '\\)', display: false},
            {left: '\\[', right: '\\]', display: true}
          ],
          throwOnError : false
        });
      });
    </script>
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <div id="nav-outer">
  <nav id="main-nav" class="outer">
    <a id="main-nav-toggle" class="nav-icon"></a>
    
      <a class="main-nav-link" href="/">Home</a>
    
      <a class="main-nav-link" href="/archives">Posts</a>
    
      <a class="main-nav-link" href="/about">About</a>
    
    <div class="main-nav-space-between"></div>
    
  </nav>
</div>
<div id="header-title">

  
</div>

      <div id="content" class="outer">
        <section id="main"><article id="post-Machine Learning Notes" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/01/13/Machine%20Learning%20Notes/" class="article-date">
  <time class="dt-published" datetime="2025-01-14T04:39:03.000Z" itemprop="datePublished">2025-01-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      machine-learning-notes
    </h1>
  

      </header>
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="lecture-2">Lecture 2</h1>
<ul>
<li>bottleneck: labeling</li>
</ul>
<h2 id="overfit">overfit</h2>
<img src="assets/image-20250302110210897.png" alt="image-20250302110210897|500" style="zoom: 33%;" />
<ul>
<li>应对 overfit: restrict the representation power -&gt; “regularization”</li>
<li>modern view: overfit 并不是问题<span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span>在 SGD 中天生的就会有 implicit regularization 来减少 overfit 的可能</li>
</ul>
<h2 id="unsupervised-learning">Unsupervised Learning</h2>
<ul>
<li>clustering</li>
<li>PCA</li>
<li>generative model</li>
<li>anomaly detection</li>
<li>dimension reduction (PCA application)</li>
</ul>
<h2 id="semi-supervised-learning">Semi-supervised Learning</h2>
<h1 id="lecture-3">Lecture 3</h1>
<h2 id="optimization">Optimization</h2>
<ul>
<li>zero-order method
<ul>
<li>only knows <span class="markdown-them-math-inline">$f(x)$</span></li>
<li>hyperparameter tuning</li>
</ul>
</li>
<li><strong>first-order method</strong>
<ul>
<li>knows <span class="markdown-them-math-inline">$f(x), f'(x)$</span></li>
</ul>
</li>
<li>second-order method
<ul>
<li>knows <span class="markdown-them-math-inline">$f(x), f'(x), f''(x)$</span></li>
<li>Hessian matrix is of size <span class="markdown-them-math-inline">$O(d^2)$</span> , <span class="markdown-them-math-inline">$d$</span> denotes the number of parameters</li>
<li>太费时间</li>
</ul>
</li>
</ul>
<h3 id="gradient-descent">Gradient descent</h3>
<p><div class="markdown-them-math-block">$$ w_{t+1}=w_t-\eta\nabla L(w_t)$$</div></p>
<ul>
<li><strong>Smoothness assumption:</strong> <span class="markdown-them-math-inline">$\|f''(w)\| \leq L$</span></li>
</ul>
<blockquote>
<p>什么叫 smoothness: 梯度函数是 L-Lipschitz 的<span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span>即</p>
<p><div class="markdown-them-math-block">$$\|\nabla f(x)-\nabla f(y)\|\leq L\|x-y\|.$$</div></p>
<p>梯度不会剧烈变化<span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span>就说明每一步的梯度下降的步长都比较稳定<span class="bd-box"><h-char class="bd bd-beg"><h-inner>。</h-inner></h-char></span></p>
</blockquote>
<ul>
<li><strong>Lemma</strong>: <span class="markdown-them-math-inline">$f'(w)$</span> 是 L-Lipschitz 当且仅当 <span class="markdown-them-math-inline">$\|f''(w)\| \leq L, \forall w \in R^n$</span></li>
</ul>
<blockquote>
<p><strong>Proof</strong></p>
<p>若 <span class="markdown-them-math-inline">$\| f''(w) \| \leq L$</span><span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span>有</p>
<p><div class="markdown-them-math-block">$$\begin{align*} \|f'(y) - f'(x)\| &amp;= \left\|\left(\int _ 0 ^ 1f''(x + \tau (y - x)) d\tau\right) \cdot (y - x) \right \| \\
&amp;\leq L \| y - x \|
\end{align*}$$</div></p>
<p>若 <span class="markdown-them-math-inline">$\| f'(y) -f '(x)\| \leq L \|y - x\|$</span><span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span>有</p>
<p><div class="markdown-them-math-block">$$\left\|\left(\int_{0}^{\alpha}f^{\prime\prime}(x+\tau s)d\tau\right)\cdot s\right\|=\parallel f^{\prime}(x+\alpha s)-f^{\prime}(x)\parallel\leq\alpha L\parallel s\parallel.$$</div></p>
<p>两边除掉 <span class="markdown-them-math-inline">$\alpha$</span> 并令 <span class="markdown-them-math-inline">$\alpha \rightarrow 0$</span> 就有 <span class="markdown-them-math-inline">$\|f''(x)\| \leq L$</span>.</p>
<p>就是对于每个 <span class="markdown-them-math-inline">$x$</span> 考虑 <span class="markdown-them-math-inline">$x$</span> 周围 <span class="markdown-them-math-inline">$\delta$</span> 的邻域</p>
</blockquote>
<ul>
<li><strong>Lemma:</strong> <span class="markdown-them-math-inline">$f'(w)$</span> 是 L-Lipschitz 时<span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span>有<div class="markdown-them-math-block">$$\mid f(y)-f(x)-\langle f^{\prime}(x),y-x\rangle\mid\leq\frac{L}{2}\parallel y-x\parallel^2.
$$</div></li>
</ul>
<blockquote>
<img src="assets/image-20250302192013008.png" alt="image-20250302192013008" style="zoom: 50%;" />
</blockquote>
<ul>
<li>当满足梯度光滑条件时<span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span>考虑学习率 <span class="markdown-them-math-inline">$\eta$</span> 的合适取值范围</li>
</ul>
<blockquote>
<p>我们有 <span class="markdown-them-math-inline">$w' = w - \eta f'(w)$</span><span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span></p>
<div class="markdown-them-math-block">$$\begin{align*}
f(w') - f(w) &amp;\leq \langle f'(w), w'- w\rangle + \frac L 2 \| w'-w\| ^ 2 \\
&amp;= - \eta \| f'(w)\|^2 + \frac {\eta ^ 2L} 2 \|f'(w)\|^2 \\
&amp;= -\eta \left(1 - \frac {\eta L} 2\right)  \|f'(w)\|^2 
\end{align*}
$$</div><p>我们希望每一次更新都有 <span class="markdown-them-math-inline">$f(w') - f(w) &lt; 0$</span><span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span>这需要 <span class="markdown-them-math-inline">$\eta &lt; \frac 2 L$</span>.</p>
<p>这意味着如果函数 <span class="markdown-them-math-inline">$f$</span> 的梯度平滑<span class="bd-box"><h-char class="bd bd-beg"><h-inner>，</h-inner></h-char></span>那么梯度下降的效果有很好的保证<span class="bd-box"><h-char class="bd bd-beg"><h-inner>。</h-inner></h-char></span></p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      
      
        <a href="/2025/01/13/Machine%20Learning%20Notes/#comments" class="article-comment-link">
          <span class="post-comments-count valine-comment-count" data-xid="/2025/01/13/Machine%20Learning%20Notes/" itemprop="commentCount"></span>
          Comments
        </a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/course-notes/" rel="tag">course notes</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2025/03/02/ZeroTier-nomachine%20%E5%AE%9E%E7%8E%B0%E6%9B%B4%E5%A5%BD%E7%9A%84%E8%BF%9C%E7%A8%8B%E6%8E%A7%E5%88%B6/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          ZeroTier+nomachine 实现更好的远程控制
        
      </div>
    </a>
  
  
    <a href="/2024/07/07/%E7%94%9F%E6%B4%BB%E8%AE%B0%E5%BD%952-0/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">
        
          生活记录2.0
        
      </div>
    </a>
  
</nav>

  
</article>



  <section id="comments" class="vcomment">

  </section>
</section>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
        <span id="busuanzi_container_site_pv" style='display:none'>Total view count: <span id="busuanzi_value_site_pv"></span></span>
<p>Powered by <a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/">Hexo</a> & Theme <a target="_blank" rel="noopener" href="https://github.com/bill-xia/hexo-theme-mashiro">Mashiro</a> & GitHub Pages</p><p>Copyright © 2024 igzat1no. LICENSE CC BY-NC-SA 4.0.</p>
      
    </div>
  </div>
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Posts</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav>
    

<script src="/js/clipboard.min.js"></script>
<script src="/js/jquery-1.4.3.min.js"></script>

<script src="/fancybox/jquery.fancybox-1.3.4.pack.js"></script>


<script src="/js/script.js"></script>




  
<script src="https://cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js"></script>

<script>
    var GUEST_INFO = ['nick','mail','link'];
    var guest_info = 'nick,mail,link'.split(',').filter(function(item){
        return GUEST_INFO.indexOf(item) > -1
    });
    var notify = 'false' == true;
    var verify = 'false' == true;
    new Valine({
        el: '.vcomment',
        notify: notify,
        verify: verify,
        appId: "k2JFn7Fvw42zZfjmoYffhjGC-gzGzoHsz",
        appKey: "pLfzf8qWKmVAAZPSJ0fXlTlg",
        placeholder: "Leave your footprints here!!",
        pageSize:'10',
        avatar:'wavatar',
        lang:'zh-cn'
    });
</script>



  </div>
</body>
</html>